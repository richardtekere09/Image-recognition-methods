{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "13sohkUy7CoNrOO1mqTvWCI0KaeXnMdsy",
      "authorship_tag": "ABX9TyMBqRT18XH/j5tHb1ECQb3/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import the libraries"
      ],
      "metadata": {
        "id": "sS_au-xdNDpd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MBT7PlDCaJc",
        "outputId": "2e2c3c6a-be88-487e-d75a-4aecc325c397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CUSTOM DATASET CLASS"
      ],
      "metadata": {
        "id": "U5C5lPLYPUpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PlantDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom Dataset for loading plant leaf images\n",
        "\n",
        "    How it works:\n",
        "    1. Scans folders and creates list of (image_path, label) pairs\n",
        "    2. __len__ returns total number of images\n",
        "    3. __getitem__ loads one image when requested\n",
        "    \"\"\"\n",
        "    def __init__(self,root_dir,transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (str): Path to Train or Test folder\n",
        "            transform: PyTorch transforms to apply to images\n",
        "        \"\"\"\n",
        "        self.root_dir=Path(root_dir)\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        #Map the labels\n",
        "        self.class_map = {\n",
        "            'Potato_sick_late': 0,\n",
        "            'Potato_sick_early': 1,\n",
        "            'Potato_healthy': 2\n",
        "        }\n",
        "\n",
        "        # Scan all folders and collect image paths\n",
        "        for class_name, label in self.class_map.items():\n",
        "          class_folder = self.root_dir/ class_name\n",
        "          if class_folder.exists():\n",
        "              all_images = (\n",
        "                    sorted(class_folder.glob(\"*.jpg\")) +    # lowercase\n",
        "                    sorted(class_folder.glob(\"*.JPG\")) +    # uppercase\n",
        "                    sorted(class_folder.glob(\"*.jpeg\")) +   # lowercase\n",
        "                    sorted(class_folder.glob(\"*.JPEG\")) +   # uppercase\n",
        "                    sorted(class_folder.glob(\"*.png\")) +    # lowercase\n",
        "                    sorted(class_folder.glob(\"*.PNG\"))      # uppercase\n",
        "                )\n",
        "\n",
        "              for img_path in all_images:\n",
        "                  self.images.append(str(img_path))\n",
        "                  self.labels.append(label)\n",
        "\n",
        "        print(f\"Loaded {len(self.images)} images from {root_dir}\")\n",
        "        print(f\"Class distribution: \", {k: self.labels.count(v) for k, v in self.class_map.items()})\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      img_path =self.images[idx]\n",
        "      image = Image.open(img_path).convert('RGB')\n",
        "      label = self.labels[idx]\n",
        "\n",
        "      # Apply transformations if specified\n",
        "      if self.transform:\n",
        "        image = self.transform(image)\n",
        "\n",
        "      return image ,label\n"
      ],
      "metadata": {
        "id": "m9OEfYG1PZFV"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA AUGMENTATION & TRANSFORMS"
      ],
      "metadata": {
        "id": "ftoACq-5WR_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training transforms WITH augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((180,180)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),     # 50% chance to flip horizontally\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ToTensor(),\n",
        "        transforms.Normalize(                       # Normalize with ImageNet stats\n",
        "        mean=[0.485, 0.456, 0.406],            # Standard for pre-trained models\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((180, 180)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n"
      ],
      "metadata": {
        "id": "l-DT6pI1WSiF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOAD DATASETS"
      ],
      "metadata": {
        "id": "F8_UpG6Nav-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = '/content/drive/MyDrive/plants/Train'\n",
        "TEST_PATH = '/content/drive/MyDrive/plants/Test'\n",
        "\n",
        "train_dataset = PlantDataset(TRAIN_PATH, transform=train_transforms)\n",
        "test_dataset = PlantDataset(TEST_PATH, transform=test_transforms)\n",
        "\n",
        "# DataLoader: Batches data, shuffles, enables parallel loading\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=20,\n",
        "    shuffle = True,\n",
        "    num_workers = 2\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=20,\n",
        "    shuffle = False,\n",
        "    num_workers = 2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmjDj610ax5J",
        "outputId": "bfd0f2a3-5191-4ade-dadc-9e8355f3d7ad"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2100 images from /content/drive/MyDrive/plants/Train\n",
            "Class distribution:  {'Potato_sick_late': 700, 'Potato_sick_early': 700, 'Potato_healthy': 700}\n",
            "Loaded 900 images from /content/drive/MyDrive/plants/Test\n",
            "Class distribution:  {'Potato_sick_late': 300, 'Potato_sick_early': 300, 'Potato_healthy': 300}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINE CNN ARCHITECTURE\n"
      ],
      "metadata": {
        "id": "_IwX8RaUhwBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PlantCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(PlantCNN,self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=3,out_channels=32, kernel_size=3,padding=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=32,out_channels=64, kernel_size=3,padding=1)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64,out_channels=128, kernel_size=3,padding=1)\n",
        "\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    # Calculate flattened size: 180 -> 90 -> 45 -> 22 after 3 pooling layers\n",
        "    # 22 * 22 * 128 = 61952\n",
        "    self.fc1 = nn.Linear(128 * 22 * 22, 256)\n",
        "    self.fc2 = nn.Linear(256,3)\n",
        "\n",
        "  def forward(self,x):\n",
        "  # Block 1: Conv -> ReLU -> Pool\n",
        "    x = self.pool(self.RELU(self.conv1(x)))\n",
        "          # Block 2\n",
        "    x = self.pool(self.relu(self.conv2(x)))  # (64, 45, 45)\n",
        "\n",
        "    # Block 3\n",
        "    x = self.pool(self.relu(self.conv3(x)))  # (128, 22, 22)\n",
        "\n",
        "    # Flatten for fully connected layers\n",
        "    x = x.view(x.size(0), -1)  # (batch_size, 128*22*22)\n",
        "\n",
        "    # Fully connected layers\n",
        "    x = self.dropout(self.relu(self.fc1(x)))\n",
        "    x = self.fc2(x)  # Raw logits (no softmax needed for CrossEntropyLoss)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Initialize model\n",
        "model = PlantCNN().to(device)\n",
        "print(f\"\\nModel architecture:\\n{model}\")\n",
        "\n",
        "# Count trainable parameters\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\nTotal trainable parameters: {total_params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQIcJLAAh1Be",
        "outputId": "94caff7f-e248-4d71-f754-c894aedbae62"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model architecture:\n",
            "PlantCNN(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc1): Linear(in_features=61952, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=3, bias=True)\n",
            ")\n",
            "\n",
            "Total trainable parameters: 15,953,987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOSS FUNCTION & OPTIMIZER"
      ],
      "metadata": {
        "id": "eQ_7aAFAqUf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CrossEntropyLoss: Combines LogSoftmax + NLLLoss\n",
        "# Perfect for multi-class classification\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Adam optimizer: Adaptive learning rate, works well for most cases\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Learning rate scheduler: Reduces LR when validation loss plateaus\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        ")"
      ],
      "metadata": {
        "id": "1LtwP4wXh_JT"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING FUNCTION"
      ],
      "metadata": {
        "id": "8CsBbA0drf7z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tvDh0WYsrgYd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}